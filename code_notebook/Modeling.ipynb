{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation,Dense,Dropout,BatchNormalization,PReLU\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = pd.read_csv('../model/train_x.csv', index_col='device_id')\n",
    "print(df_train_x.shape)\n",
    "\n",
    "df_test_x = pd.read_csv('../model/test_x.csv', index_col='device_id')\n",
    "print(df_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_id = df_train_x.index\n",
    "print(df_train_id.shape)\n",
    "\n",
    "df_test_id = df_test_x.index\n",
    "print(df_test_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_train_x = preprocessing.normalize(df_train_x)\n",
    "array_test_x = preprocessing.normalize(df_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_y = pd.read_csv('../matrix_for_model/train_y.csv', header=None)\n",
    "print(df_train_y.shape)\n",
    "\n",
    "df_train_y_onehot = pd.get_dummies(df_train_y)\n",
    "array_train_y = df_train_y_onehot.values\n",
    "array_train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection according to random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(random_state=1).fit(array_train_x, array_train_y)\n",
    "print(\"clf.feature_importances_ :\",clf.feature_importances_)\n",
    "\n",
    "col_filter = SelectFromModel(clf,prefit=True,threshold=1.0*(clf.feature_importances_.mean()))\n",
    "array_train_x = col_filter.transform(array_train_x)\n",
    "array_train_x.shape   # (74645, 1581)\n",
    "\n",
    "array_test_x = col_filter.transform(array_test_x)\n",
    "array_test_x.shape  # (112071, 1581)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function of submit dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_df(df_test_id, array_test_y):\n",
    "    cols = ['device_id', 'F23-','F24-26','F27-28','F29-32','F33-42','F43+','M22-','M23-26','M27-28','M29-31','M32-38','M39+']\n",
    "    df_result = pd.DataFrame(columns=cols)\n",
    "    df_result['device_id'] = df_test_id\n",
    "    df_result[['F23-','F24-26','F27-28','F29-32','F33-42','F43+','M22-','M23-26','M27-28','M29-31','M32-38','M39+']] = array_test_y\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Backpropagation Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define modelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_modeling(train_x):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=train_x.shape[1], init='normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50, init='normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn_modeling(array_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = nn_model.fit(array_train_x, array_train_y, validation_split=0.1, batch_size=512, epochs=7)\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='train accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test_y = nn_model.predict(array_test_x)\n",
    "df_result = submit_df(df_test_id, array_test_y)\n",
    "df_result.to_csv('../submit/nn_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_modeling(train_x, train_y):\n",
    "    rf = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [100],\n",
    "    'max_features': [3],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [10],\n",
    "    'n_estimators': [500]\n",
    "    }\n",
    "    grid_rf = GridSearchCV(rf, param_grid, n_jobs=-1, cv=3)\n",
    "    model = grid_rf.fit(train_x, train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env JOBLIB_TEMP_FOLDER=/tmp\n",
    "forest_model = rf_modeling(array_train_x, array_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test_y = forest_model.predict(array_test_x)\n",
    "df_result = submit_df(df_test_id, array_test_y)\n",
    "df_result.to_csv('../submit/forest_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factorize train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = pd.factorize(df_train_y[0])\n",
    "array_train_y = factor[0]\n",
    "definitions = factor[1]\n",
    "print(array_train_y)\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train to 90% for training and 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(array_train_x, array_train_y, test_size=0.1)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_modeling(train_x, train_y, val_x, val_y):\n",
    "    # Save data to xgb.DMatrix\n",
    "    data_val  = xgb.DMatrix(val_x, label=val_y)\n",
    "    data_train = xgb.DMatrix(train_x, label=train_y)\n",
    "    \n",
    "    #Set parameters\n",
    "    param = {}\n",
    "    param['booster']='gbtree'\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['tree_method'] = 'hist'\n",
    "    param['silent']=1\n",
    "    param['max_depth']= 6\n",
    "    param['num_class'] = 12\n",
    "    \n",
    "    eval_list  = [(data_train,'train'),(data_val,'validation')]\n",
    "    num_round = 20\n",
    "    eval_history={}\n",
    "\n",
    "    # Train model\n",
    "    xgb_model = xgb.train(param, data_train, num_round, eval_list, \n",
    "                          evals_result=eval_history, verbose_eval=False)\n",
    "    \n",
    "    #Show process\n",
    "    mlogloss_train=eval_history['train']['mlogloss']\n",
    "    mlogloss_validation=eval_history['validation']['mlogloss']\n",
    "    plt.plot(mlogloss_train,ms=10,marker='.',label='train_eval')\n",
    "    plt.plot(mlogloss_validation,ms=10,marker='v',label='validation_eval')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate result\n",
    "    print(\"mlogloss:\", xgb_model.eval(data_val))\n",
    "  \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb_modeling(train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xgb.DMatrix(array_test_x)\n",
    "array_test_y = xgb_model.predict(x)\n",
    "df_result = submit_df(df_test_id, array_test_y)\n",
    "df_result.to_csv('../submit/xgb_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
